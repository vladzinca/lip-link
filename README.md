# lip-link

As Machine Learning has been expanding its scope more and more in the last few decades, new kinds of everyday problems begin to benefit from it. This is especially relevant to areas concerning human accesibility, with these new techniques allowing for great improvement.

One such case is lip reading, which represents the ability to understand what is being said by simply looking at one's movement of the mouth during speech.

We propose a deep learning lip reading app that, given a short of video of a speaking person, can output the content of the discourse as text. We aim to do this by analyzing state-of-the-art research in this area and producing a Python-based program that implements the studied architecture.

The goal of this project is to set the basis of a more complex system which, in time, may extend its portability to virtual reality and smart devices.
